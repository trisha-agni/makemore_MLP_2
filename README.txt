Description:

What I learned:
Python:

Math:

AI:
- tanh saturation
  - occurs for very large positive or negative inputs
  - tanh output approaches -1 or 1
  - tanh graph flattens out as it approaches -1 or 1
  - effect: vanishing gradients
- dead neurons
- batch normalization
  - stabilizes training
